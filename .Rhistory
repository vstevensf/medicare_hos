# uncomment and run if packages not installed yet in your environment
# install.packages("dplyr")
# install.packages("lme4")
# load appropriate libraries
library(dplyr)
library(lme4)
# ---------------------------------------------------- PART 1
# read in polling data -- replace with appropriate directory
poll <- read.csv("C:\\Users\\Victoria\\Downloads\\HW3-polling_data.csv") %>% select(-1)
poll$race <- factor(poll$race, levels = c("tiger", "bear")) # Fixing a minor quirk of the data
# Part 1: State-level estimates from national polls
# statistical model to predict voter support based on race, college degree, & state
my_model <- glmer(choice ~ race + college + (1 | state), data = poll, family = "binomial")
# save prediction for each person
poll$pred <- predict(my_model, type = "response")
# save prediction for each group in a 4x25 matrix
grouped <- group_by(poll, state, race, college)
group_predictions <- summarise(grouped, mean = mean(pred))
group_predictions # Take a look at Pooh's polling numbers by group (print)
# # Q2 -- extracting max and min voters
# # install.packages('tibble') # required library
# # library('tibble')
# group_predictions <- as.data.frame(group_predictions)
# typeof(group_predictions)
# group_predictions %>% slice_max(mean) # strongest supporter(s)
# group_predictions %>% slice_min(mean) # weakest supporter(s)
group_predictions <- matrix(group_predictions$mean, ncol = 25, nrow = 4)
# multiply these group predictions by each group’s share of its state
# population, and sum over all the groups.
# get info from census data (replace file with appropriate directory)
census <- read.csv("C:\\Users\\Victoria\\Downloads\\HW3-census_data.csv", row.names = 1)
census # print to console
# now the arithmetic
MrP_estimates <- colSums(census * group_predictions)
MrP_estimates
# # Q1: extract state that's strongest and weakest for Pooh
# install.packages('tibble') # required library
# library('tibble')
# # make it a dataframe
# enframe(MrP_estimates, name = "state", value = "estimate")
# MrP_estimates <- as.data.frame(MrP_estimates)
# typeof(MrP_estimates)
# names(MrP_estimates)[0] <- 'state'
# names(MrP_estimates)[1] <- 'estimates'
# # library for max and min
# install.packages('tidyverse')
# library(tidyverse)
# # df[which.min(MrP_estimates$estimates),]
# MrP_estimates %>% slice_max(estimates) # strongest state
# MrP_estimates %>% slice_min(estimates) # weakest state
# Compare how much closer this is to the true values used to generate
# these data than the simple state averages are
truth <- c(0.466, 0.405, 0.499, 0.421, 0.391, 0.362, 0.389, 0.413, 0.346, 0.512, 0.491, 0.467, 0.499,
0.417, 0.468, 0.417, 0.597, 0.507, 0.419, 0.441, 0.407, 0.385, 0.504, 0.554, 0.556)
simple <- poll %>% group_by(state) %>% summarise(avg = sum(choice)/n())
simple_off_by <- simple$avg - truth
MrP_off_by <- MrP_estimates - truth
cat("On average, simple average off by", 100*round(mean(abs(simple_off_by)), 3), "percent")
cat("On average, MrP off by", 100*round(mean(abs(MrP_off_by)), 3), "percent")
# -----------------------------------
# use our state-level data to see who gets a majority of the vote in each state
# and award electors. Then we’ll add up the number of electors, and see who
# comes out with a majority.
state_means <- MrP_estimates
state_electors <- round(table(poll$state)/10) + 2
state_electors
results <- rep(NA, 1000)
# treat state-level outcomes as random draws, simulate election 1000 times
for (i in 1:1000){
state_results <- rnorm(n = 25, mean = state_means, sd = .03) # get state results
pooh_state_wins <- state_results > 0.5 # greater than fifty percent?
pooh_electors <- pooh_state_wins*state_electors # If so, give Pooh the electors.
results[i] <- sum(pooh_electors) >= (sum(state_electors)/2) # More than half the electors?
}
#Pooh winning percentage
sum(results)/1000
# second simulation, with national-level random shock
for (i in 1:1000){
state_results <- rnorm(n = 25, mean = state_means, sd = .03) # get state results
national_shock <- rnorm(n = 1, mean = 0, sd = .02) # national-level random shock
national_shock
pooh_state_wins <- state_results > 0.5 # greater than fifty percent?
pooh_electors <- pooh_state_wins*state_electors # If so, give Pooh the electors.
results[i] <- sum(pooh_electors) >= (sum(state_electors)/2) # More than half the electors?
}
# second simulation, with national-level random shock
for (i in 1:1000){
state_results <- rnorm(n = 25, mean = state_means, sd = .03) # get state results
national_shock <- rnorm(n = 1, mean = 0, sd = .02) # national-level random shock
print(national_shock)
pooh_state_wins <- state_results > 0.5 # greater than fifty percent?
pooh_electors <- pooh_state_wins*state_electors # If so, give Pooh the electors.
results[i] <- sum(pooh_electors) >= (sum(state_electors)/2) # More than half the electors?
}
# second simulation, with national-level random shock
for (i in 1:1000){
state_results <- rnorm(n = 25, mean = state_means, sd = .03) # get state results
national_shock <- rnorm(n = 1, mean = 0, sd = .02) # national-level random shock
# print(national_shock)
total_results <- state_results + national_shock
pooh_state_wins <- total_results > 0.5 # greater than fifty percent?
pooh_electors <- pooh_state_wins*state_electors # If so, give Pooh the electors.
results[i] <- sum(pooh_electors) >= (sum(state_electors)/2) # More than half the electors?
}
#Pooh winning percentage
sum(results)/1000
# second simulation, with national-level random shock
for (i in 1:1000){
state_results <- rnorm(n = 25, mean = state_means, sd = .03) # get state results
national_shock <- rnorm(n = 1, mean = 0, sd = .02) # national-level random shock
# print(national_shock)
total_results <- state_results + national_shock
pooh_state_wins <- total_results > 0.5 # greater than fifty percent?
pooh_electors <- pooh_state_wins*state_electors # If so, give Pooh the electors.
results[i] <- sum(pooh_electors) >= (sum(state_electors)/2) # More than half the electors?
}
#Pooh winning percentage
sum(results)/1000 # = 0.121 in my run of this simulation
national_shock <- rnorm(n = 1, mean = 0, sd = .02) # national-level random shock
# second simulation, with national-level random shock
for (i in 1:1000){
state_results <- rnorm(n = 25, mean = state_means, sd = .03) # get state results
national_shock <- rnorm(n = 1, mean = 0, sd = .02) # national-level random shock
# print(national_shock)
total_results <- state_results + national_shock
pooh_state_wins <- total_results > 0.5 # greater than fifty percent?
pooh_electors <- pooh_state_wins*state_electors # If so, give Pooh the electors.
results[i] <- sum(pooh_electors) >= (sum(state_electors)/2) # More than half the electors?
}
#Pooh winning percentage
sum(results)/1000 # = 0.147 in my run of this simulation
# second simulation, with national-level random shock
for (i in 1:1000){
state_results <- rnorm(n = 25, mean = state_means, sd = .03) # get state results
national_shock <- rnorm(n = 1, mean = 0, sd = .02) # national-level random shock
# print(national_shock)
total_results <- state_results + national_shock
pooh_state_wins <- total_results > 0.5 # greater than fifty percent?
pooh_electors <- pooh_state_wins*state_electors # If so, give Pooh the electors.
results[i] <- sum(pooh_electors) >= (sum(state_electors)/2) # More than half the electors?
}
#Pooh winning percentage
sum(results)/1000 # = 0.147 in my run of this simulation
q()
setwd("C:\Users\Victoria\Desktop\medicare")
setwd("C:\\Users\\Victoria\\Desktop\\medicare")
## Set working directory -- change as needed (have to access CSVs below)
# setwd("/Users/M296398/Desktop/medicare_HOS_ortho/stats redo w strat")
setwd("C:\\Users\\Victoria\\Desktop\\medicare")
## Read in PUF files -- change filenames as needed
df_1998 <- read.csv("C1_1998_PUF.csv") # Cohort 1, 1998 = 134076 x 200
df_2020 <- read.csv("C23A_2020_PUF.csv") # Cohort 23, 2020 = 281791 x 160
### Data Preprocessing
## Remove unnecessary cols -- we want demographics, arthritis status, and PROMs
c1_cols <- c(
"CASE_ID", "AGE", "RACE", "GENDER", "MRSTAT", "EDUC", "B1ATHHIP", "B1GENHTH",
"B1MODACT", "B1CLMBSV", "B1PACMPL", "B1PLMTKW", "B1EACMPL", "B1ENTCRF",
"B1PNINTF", "B1PCEFUL", "B1ENERGY", "B1BLSAD", "B1SCLACT", "B1DIFBTH",
"B1DIFDRS", "B1DIFEAT", "B1DIFCHR", "B1DIFWLK", "B1DIFTOL", "B1DIABET",
"B1ANGCAD", "B1HIGHBP", "B1CHF", "B1AMI", "B1GI_ETC", "B1COPD_E", "B1SMKFRQ",
"B1STROKE"
)
c23_cols <- c(
"CASE_ID", "AGE", "RACE", "GENDER", "MRSTAT", "EDUC", "B23CCARTHIP",
"B23VRGENHTH", "B23VRMACT", "B23VRSTAIR", "B23VRPACCL", "B23VRPWORK",
"B23VRMACCL", "B23VRMWORK", "B23VRPAIN", "B23VRCALM", "B23VRENERGY",
"B23VRDOWN", "B23VRSACT", "B23ADLBTH", "B23ADLDRS", "B23ADLEAT",
"B23ADLCHR", "B23ADLWLK", "B23ADLTLT", "B23CCDIABET", "B23CC_CAD",
"B23CCHBP", "B23CC_CHF", "B23CCMI", "B23CCGI", "B23CC_COPD", "B23SMOKE",
"B23CCSTROKE"
)
filtered_df_1998 <- df_1998[, c1_cols]
filtered_df_2020 <- df_2020[, c23_cols]
## Standardize column names between the two cohorts
new_col_names <- c(
"CASE_ID", "AGE", "RACE", "GENDER", "MRSTAT", "EDUC", "Arthritis", "General_Health",
"Mod_Activity", "Stairs", "Phys_Amount_Limit", "Phys_Type_Limit", "Emo_Amount_Limit",
"Emo_Carefulness", "Pain_Work", "Peace", "Energy", "Down", "Social_Interference",
"Bathing", "Dressing", "Eating", "Chairs", "Walking", "Toilet", "Diabetes",
"ANG_CAD", "Hypertension", "CHF", "MI", "IBD", "COPD", "Smoking_Status", "Stroke"
)
# Copy and replace column names
renamed_df_1998 <- `names<-`(filtered_df_1998, replace(names(filtered_df_1998), match(c1_cols, names(filtered_df_1998)), new_col_names))
renamed_df_2020 <- `names<-`(filtered_df_2020, replace(names(filtered_df_2020), match(c23_cols, names(filtered_df_2020)), new_col_names))
## Remove patients that didn't answer all the questions (NAs/blanks)
# Checking the datatypes within each column for each cohort -- make sure they match up
# Loop through each column name
for (col in new_col_names) {
# Check its datatypes
unique_types <- unique(sapply(renamed_df_1998[[col]], typeof))
unique_types2 <- unique(sapply(renamed_df_2020[[col]], typeof))
# and print
cat("Column:", col, "\n")
print("cohort 1")
print(unique_types)
print("cohort 23")
print(unique_types2)
cat("\n")
} # all cols are of type integer except CASE_ID, which is char
# Handle char column = CASE_ID
# Function to check if a char value is "empty"
is_empty_char <- function(x) {
is.null(x) || is.na(x) || x == "" || grepl("^\\s*$", x) || x == "\u00A0" || x == "\u200B" || x == "\n"
}
# Apply the empty check to the 'CASE_ID' column
empty_rows_1998 <- sapply(renamed_df_1998$CASE_ID, is_empty_char)
empty_rows_2020 <- sapply(renamed_df_1998$CASE_ID, is_empty_char)
# Filter the data frames to remove rows with "empty" values in the 'CASE_ID' column
# This didn't make a difference but useful check to have
cleaned_1998 <- renamed_df_1998[!empty_rows_1998, ]
cleaned_2020 <- renamed_df_2020[!empty_rows_2020, ]
# Handle integer columns
# Function to check if a integer value is "empty"
is_empty_integer <- function(x) {
is.null(x) || is.na(x) || length(x) == 0
}
# Apply the empty check to the rest of the columns
cols_to_check <- new_col_names[2:length(new_col_names)]
for (col in cols_to_check) {
# remove rows with "empty" values
cleaned_again_1998 <- cleaned_1998[!sapply(cleaned_1998[[col]], is_empty_integer), ]
cleaned_again_2020 <- cleaned_2020[!sapply(cleaned_2020[[col]], is_empty_integer), ]
}
# double check that we really got rid of all the NAs/empties
# Use complete.cases() to remove rows with NA in the specified columns
cleanest_1998 <- cleaned_again_1998[complete.cases(cleaned_again_1998[, new_col_names]), ]
cleanest_2020 <- cleaned_again_2020[complete.cases(cleaned_again_2020[, new_col_names]), ]
## Select the patients with arthritis & removal of extraneous data
#create cohorts of patients with arthritis
#1 = yes, 2 = no -- so keep the rows that have 1 as the value under arthritis
arth_1998 <- cleanest_1998[cleanest_1998$Arthritis == 1, ]
arth_2020 <- cleanest_2020[cleanest_2020$Arthritis == 1, ]
# Remove rows where GENDER == 3
final_1998 <- arth_1998[arth_1998$GENDER != 3, ]
final_2020 <- arth_2020[arth_2020$GENDER != 3, ]
## Make sure all scoring is the same (differs from year to year, refer to HOS docs)
# VR12: Transforming "Phys_Amount_Limit", "Phys_Type_Limit", "Emo_Amount_Limit", "Emo_Carefulness" for 2020
# "Phys_Amount_Limit" - 1998 = 1 (Yes) 2 (No), 2020 1 (No) 2-5 (Yes)
# "Phys_Type_Limit" - 1998 = 1 (Yes) 2 (No), 2020 1 (No) 2-5 (Yes)
# "Emo_Amount_Limit" - 1998 = 1 (Yes) 2 (No), 2020 1 (No) 2-5 (Yes)
# "Emo_Carefulness" - 1998 = 1 (Yes) 2 (No), 2020 1 (No) 2-5 (Yes)
final_2020$Phys_Amount_Limit <- ifelse(final_2020$Phys_Amount_Limit == 1, 2, 1)
final_2020$Phys_Type_Limit <- ifelse(final_2020$Phys_Type_Limit == 1, 2, 1)
final_2020$Emo_Amount_Limit <- ifelse(final_2020$Emo_Amount_Limit == 1, 2, 1)
final_2020$Emo_Carefulness <- ifelse(final_2020$Emo_Carefulness == 1, 2, 1)
# Transforming ADL variables "Bathing", "Dressing", "Eating", "Chairs", "Walking", "Toilet" for 2020
# "Bathing" - 1998 = 1 (Can't do) 2 (Yes, difficult) 3 (No difficulty), 2020 = 1 (no difficulty) 2 (yes, difficult) 3 (can't do)
# "Dressing" - 1998 = 1 (Can't do) 2 (Yes, difficult) 3 (No difficulty), 2020 = 1 (no difficulty) 2 (yes, difficult) 3 (can't do)
# "Eating" - 1998 = 1 (Can't do) 2 (Yes, difficult) 3 (No difficulty), 2020 = 1 (no difficulty) 2 (yes, difficult) 3 (can't do)
# "Chairs" - 1998 = 1 (Can't do) 2 (Yes, difficult) 3 (No difficulty), 2020 = 1 (no difficulty) 2 (yes, difficult) 3 (can't do)
# "Walking" - 1998 = 1 (Can't do) 2 (Yes, difficult) 3 (No difficulty), 2020 = 1 (no difficulty) 2 (yes, difficult) 3 (can't do)
# "Toilet" - 1998 = 1 (Can't do) 2 (Yes, difficult) 3 (No difficulty), 2020 = 1 (no difficulty) 2 (yes, difficult) 3 (can't do)
final_2020$Bathing <- ifelse(final_2020$Bathing == 1, 3, ifelse(final_2020$Bathing == 2, 2, 1))
final_2020$Dressing <- ifelse(final_2020$Dressing == 1, 3, ifelse(final_2020$Dressing == 2, 2, 1))
final_2020$Eating <- ifelse(final_2020$Eating == 1, 3, ifelse(final_2020$Eating == 2, 2, 1))
final_2020$Chairs <- ifelse(final_2020$Chairs == 1, 3, ifelse(final_2020$Chairs == 2, 2, 1))
final_2020$Walking <- ifelse(final_2020$Walking == 1, 3, ifelse(final_2020$Walking == 2, 2, 1))
final_2020$Toilet <- ifelse(final_2020$Toilet == 1, 3, ifelse(final_2020$Toilet == 2, 2, 1))
## Combining the cohorts into one dataframe (necessary for propensity matching)
# Add a binary cohort variable indicating the...cohort
final_1998$cohort <- 0
final_2020$cohort <- 1
View(final_1998)
View(final_2020)
install.packages("rstudioapi")
library(rstudioapi)
barbie_dark <- "https://raw.githubusercontent.com/emhogg/barbie_r_studio_themes/main/Barbie_Dark.rstheme"
rstudioapi::addTheme(barbie_dark, apply = TRUE)
# Combine the cohort dataframes (vertical stack)
#TODO treated vs control??
# column names, number, and datatype must match (made sure of this above w preprocessing)
combined_data <- rbind(final_1998, final_2020)
