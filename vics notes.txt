"Phys_Amount_Limit" - 1998 = 1 (Yes) 2 (No), 2020 1 (No) 2-5 (Yes)
"Phys_Type_Limit" - 1998 = 1 (Yes) 2 (No), 2020 1 (No) 2-5 (Yes)
"Emo_Amount_Limit" - 1998 = 1 (Yes) 2 (No), 2020 1 (No) 2-5 (Yes)
"Emo_Carefulness" - 1998 = 1 (Yes) 2 (No), 2020 1 (No) 2-5 (Yes)

"Bathing" - 1998 = 1 (Can't do) 2 (Yes, difficult) 3 (No difficulty), 2020 = 1 (no difficulty) 2 (yes, difficult) 3 (can't do)
"Dressing" - 1998 = 1 (Can't do) 2 (Yes, difficult) 3 (No difficulty), 2020 = 1 (no difficulty) 2 (yes, difficult) 3 (can't do)
"Eating" - 1998 = 1 (Can't do) 2 (Yes, difficult) 3 (No difficulty), 2020 = 1 (no difficulty) 2 (yes, difficult) 3 (can't do)
"Chairs" - 1998 = 1 (Can't do) 2 (Yes, difficult) 3 (No difficulty), 2020 = 1 (no difficulty) 2 (yes, difficult) 3 (can't do)
"Walking" - 1998 = 1 (Can't do) 2 (Yes, difficult) 3 (No difficulty), 2020 = 1 (no difficulty) 2 (yes, difficult) 3 (can't do)
"Toilet" - 1998 = 1 (Can't do) 2 (Yes, difficult) 3 (No difficulty), 2020 = 1 (no difficulty) 2 (yes, difficult) 3 (can't do)


Methods: The Medicare Health Outcomes Survey (HOS) Database was queried for all patients who reported a diagnosis of hip or knee arthritis in the first (1998) and latest (2020) defined cohorts. The cohorts were successfully propensity score matched for age, gender, race, education status, diabetes, hypertension, congestive heart failure, chronic obstructive pulmonary disease, and smoking status. Patients received various treatments, including non-operative and operative modalities. Chi-squared analysis was used to compare 18 components of the Veterans RAND 12 Item Health Survey (VR-12) and activities of daily living (ADL) between cohorts.   

Note here -- you may want to expand on this - namely define more clearly your cohorts. Reading further down, it becomes clearer, but would be explicitly state 2 cohorts, a 1998 and a 2020 cohort. Feel free to alter my suggested change. I think already completed

Results: Each matched cohort included 22,001 patients. The 2020 cohort reported lower scores than the 1998 cohort on each component of the VR-12, most notably physical and emotional health on activity level. Compared to the 1998 cohort, the 2020 cohort more frequently reported reduced daily activity (23.3% increase, p < 0.05) and more limitations in activity performance due to physical health (26.3% increase, p < 0.05) (Table 1). Patients in the 2020 cohort more frequently reported a reduced ability to bring daily activities to completion (15.0% increase, p < 0.05) and interference in social activities due to emotional health (17.1% increase, p < 0.05) (Table 2). Capacity to perform activities of daily living (ADLs), including bathing, dressing, eating, getting in and out of chairs, walking, using the toilet, was significantly diminished in the 2020 cohort relative to the 1998 cohort (p < 0.05 for all) (Table 3). 

Conclusions: Despite over two decades of advancement in management of hip and knee osteoarthritis, Medicare patients with OA reported diminished physical and emotional health functioning and capacity for ADLs in 2020 relative to 1998. This population is a significant and growing cost driver for the US healthcare system – both directly through medical care and indirectly through lost productive life years and an increased caregiver burden. Our results highlight the need to improve cost-effectiveness in management of OA patients and improve delivery of operative and non-operative care to a disabled population.   

7/17/24 Vic's Notes

OVERALL: downtrend in PROMs (patient-reported outcome measures, specifically VR-12 and ADLs) in Medicare arthritis patients from 1998 to 2023

1. Imports: dplyr/tidyr for data manipulation, readxl/writexl for reading and writing excel files, e1071 for stats, and MatchIt for propensity matching
2. Import 1998 and 2023 HOS files (which have been reformatted from ascii txt to csv, and matched columns by question)
3. Data cleaning and prep: handling missing values & filtering and creating relevant columns --> selected for patients with arthritis of hip or knee, narrowed down to questions from VR-12 and ADLs (TODO: total = 34)
4. Statistics: propensity score matching to create comparable groups from the 1998 & 2023 datasets -- covariates used to estimate propensity score and categorize subject as treatment or control group = age, gender, diabetes, HTN, CHF, COPD, smoking status, and arthritis; method = nearest neighbor matching (each "treated" subject is matched to the "control" subject with the closest propensity score; exact matching variables = gender, age, arthritis (further reducing potential confounding) --> basically a) propensity score calculation based on specified covariates, b) nearest neighbor matching matches each treatment subject to a control subject with the closest propensity score, with exact matching on gender/age/arthritis, then c) creates and extracts completed matched dataset used in further analysis to estimate treatment effect while controlling for the specified covariates. MATCHING IS FOR CAUSAL INFERENCE. TODO: weird that race and education came out to p = 1 even though we didn't exact match on that....suspicious. but MRSTAT completely changed
5. Statistics, cont.: various chi-squared tests to examine changes in demographic and health-related factors over time

Final results: two data frames for both years, of patients with arthritis who filled out all the relevant questions -- sample size of each is 22,001

Copy and paste last 3 lines of code for each var of interest

Did we match on additional variables? Rn it's age, gender, and various comorbidities -- could be worth matching on race and educational status (so the demographics are the exact same and look at outcome measures more validly)

Did the matching and code to assess all vars on both the matched and unmatched cohorts -- we report only the matched findings? -- attach the couple papers that guide the vars she chose for matched cohort analysis (and maybe described methodology for matching HOS cohorts = what vars to match on, doesn't even have to be HOS study, just any database that describes matching criteria that is not elixhauser or Carlson --> initially thought gender, age, hypertension, chf, stroke, cold, diabetes, smoking status

2020 vs 1998 because interesting assessment of trends over time

Did we run two analyses, one including race/edu but not the other -- we better isolate outcomes measures by matching SES varsity but running both could be useful as a sensitivity analysis -- if survey participants were vastly different in terms of SES (prolly not but reviewers might not realize that), it could impact the validity of the findings

He did exclude some columns like "cancer treatment" ones because very few ppl filled those out so if they were included, the sample size would be 1/5 of what we have now (see google sheet). He also included within-year comparisons between arthritis and non-arthritis cohorts to see if there were any varsity that didn't have a different in 1998 but did have one in 2023

Unknown if these patients have their OA treated at the time of survey (and treatment modality -- non-op treatments vs arthroplasty) --> would need to purchase restricted identifier files to link HOS survey data to individual patient records (can't get it, but what about knowing the total number in each cohort who have an arthroplasty?) -- treatment modalities were not collected in this survey

For abstract: images -- table comparing all the outcomes we considered, or two bar graphs (1 for vs12 and 1 for ASLs)?

Aaaaand all the stuff I did first: original doc outline -- converted ASCII txt files to CSV -- and HOS documentation use for indices. Data wasn't consitent/exist for every year of HOS but overall important questions (ADLs, quality of life, etc) have been present since 1998

Irb exempt all study data is publicly available and does not contain patient information, no specific direct person identifiers. No clinical trials registration. No conflicts of interest

Title: Burden of Knee and Hip Osteoarthritis on US Medicare Recipients
Primary Null Hypothesis: Patients with a history of knee/hip OA will have lower VR-12 PCS and MCS scores at baseline and follow-up compared to patients without history of knee/hip OA. 
Secondary Null Hypothesis: Patients with a history of knee/hip OA will have lower VR-12 PCS and MCS scores and increased likelihood of comorbid medical conditions at baseline and follow-up compared to patients without history of knee/hip OA.

Chose knee and hip to limit scope, another survey question in HOS talks about hand and wrist OA

Some VR-12 component responses in later years were converted from categorical to binary outcomes to compare cohorts which may have impacted the characterization and observed changes of these components.

Refer to limitations in draft and include choices made in the methods section neutrally

------------
TODO: REALLY check that the column names and scoring are matching up frfrfr, especially for classifications (for demographics, arthritis, and certain ASLs which Annika checked). And check that the excel results sheets are copied over correctly (see next sentence for reproducibility)
TODO: optimize code for stats analysis and make sure reproducible

TODO: propensity score matching -- Warning message:
Fewer control units than treated units in some `exact` strata; not all treated units will get a match. 

TODO: yates continuity correction?

TODO: get Annikas code where she changed the scoring stuff

TODO: create flowcharts showing a) how we chose patients and b) how we matched them

TODO: double check preprocessing -- NAs vs blanks, variable types in each column

TODO: check in docs for things that are outliers (such as gender = 3)

Some of the changes I made in my code/original output:
- some values were copied over wrong in the results excel, I ran vik/annikas code to replicate
- the p values were sus (1 or <2.2e-16) TODO
- TODO standardize and clean up the preprocessing

---------------------
add a pre and post chi square test to compare the categorical variables that may be confounders, and determine the appropriate covariates we should call upon the matching (kinda prooving that the var combo we used for that was optimal and we r controlling the most we can). and it ensures that any differences observed in outcomes are not due to differences in these covariates but rather due to the "treatment" effect (which in this case is the two time points, and seeing differences in PROMs with less confounding from the comorbidities we chose to account for before matching). it allows us to assess the balance of the cohorts on important categorical variables an ensures that the propensity score matching has effectively reduced confoundin, leading to more reliable and valid comparisons of outcomes.
we used chi because we only have categorical variables (TODO double check this), while a students t test would be used for continuous variables

TODO The bal.tab() function provides a table of balance statistics, including standardized mean differencesSTANDARDIZED MEAN DIFFERENCES check (for after matching) the balance achieved by matching.

do we wanna do linear or multivariable regression to create predictive models? just to really hammer in the point? TODO would this be appropriate between only two time points. or it could be a "future direction" to really make a predictive model based on the  HOS data by taking into account all the cohorts between 1998 and 2024 (if possible). or get our hands on the identifying data (get funding)

TODO: more exact p value from the chi sq comparisons

One to one, many-to-one, one-to-many, full matching, Weighting Methods: Inverse probability of treatment weighting (IPTW) and other weighting methods can be seen as a way to use all available data by weighting individuals according to their propensity scores, rather than discarding unmatched units.

Direction of comparison

Which method

Which stats after matching

Logistic regression for stratification?

Love plot

Appendix

Pre and post matched patients going through chisel or whatever I use (to ensure successful matching) -- this will choose the comorbiditis/variables to use in the matching !!! TODO

Some of the changes I made in my code/original output:
- some values were copied over wrong in the results excel, I ran vik/annikas code to replicate
- the p values were sus (1 or <2.2e-16) TODO
- TODO standardize and clean up the preprocessing
- got rid of redundancy in covariates vs exact matching in matchit() fxn

------
Here’s a summary of the statistical methods used in the cohort analysis and the reasons for choosing each:

1. **Propensity Score Matching (Nearest Neighbor Method)**:
   - **Purpose**: To reduce treatment assignment bias and simulate randomization between the TSA (Total Shoulder Arthroplasty) and HA (Hemiarthroplasty) cohorts.
   - **Why Chosen**: This method helps create balanced groups by matching patients with similar characteristics, ensuring that the comparison between the two cohorts is more accurate and less biased.

2. **Univariate Logistic Regression**:
   - **Purpose**: To assess the relationship between a single predictor variable and the outcome, identifying variables that show a significant association.
   - **Why Chosen**: This initial analysis helps identify potential predictors or risk factors that may be important for further analysis.

3. **Bivariate Analysis (Student’s t-Test and Chi-Square Test)**:
   - **Purpose**:
     - **Student’s t-Test**: To compare continuous variables (e.g., age) between the two cohorts.
     - **Chi-Square Test**: To compare categorical variables (e.g., comorbidities, complications) between the two cohorts.
   - **Why Chosen**: These tests allow for the straightforward comparison of basic patient demographics, comorbidities, and complications between the two groups, helping to identify any significant differences.

4. **Multivariable Logistic Regression**:
   - **Purpose**: To analyze the relationship between multiple predictor variables and the outcome while controlling for potential confounders (e.g., age, comorbidities).
   - **Why Chosen**: This method adjusts for confounding variables and identifies independent predictors of complications, providing a more comprehensive understanding of risk factors.

5. **Multivariable Logistic Regression with Robust Error Variance**:
   - **Purpose**: To identify risk factors for complications after TSA and HA with more precise estimates by accounting for potential heteroscedasticity (variability in the data).
   - **Why Chosen**: The robust error variance helps to ensure that the standard errors of the estimated coefficients are accurate, leading to more reliable statistical inferences, especially when there may be variations in the data that could affect the standard errors.

### Summary List:
1. **Propensity Score Matching**: To reduce bias and simulate randomization between cohorts.
2. **Univariate Logistic Regression**: To identify individual predictors associated with the outcome.
3. **Bivariate Analysis**:
   - **Student’s t-Test**: To compare continuous variables between cohorts.
   - **Chi-Square Test**: To compare categorical variables between cohorts.
4. **Multivariable Logistic Regression**: To adjust for confounders and identify independent risk factors.
5. **Multivariable Logistic Regression with Robust Error Variance**: To ensure accurate estimates and identify reliable risk factors for complications.

----
TODO "covariate balance checks" -- significant p values on pre match chi square for categorical variables
TODO sensitivity analysis -- to assess unmeasured confounding concentrated in the treated contrary to prediction
TODO: extra demographics to check" pull edema (could be under chi), cariogenic shock, current vs former smoking, high cholesterol
CVA/TIA
Cancer
Renal

TODO: interactions in the propensity-score model?

Variance Ratios and Interactions:

The researchers looked at more detailed checks, like the ratio of the variability (variance) of covariates between the groups and interactions between variables (how variables like age and gender might work together).
If the propensity score model is correctly specified, these detailed checks should show that the groups are more similar (e.g., variance ratios close to 1).
When the propensity score model was mis-specified, these detailed checks often showed problems (e.g., variance ratios different from 1).
2. Significance Testing:
What It Is: Significance testing (like p-values) is often used to compare covariates between treated and untreated groups after matching to check if they are balanced.
Why It's Limited: There are two main issues:
Reduced Power: After matching, the sample size is smaller, which makes it harder to detect imbalances. A lack of significant differences might just be due to having fewer data points, not because the groups are truly balanced.
Sample-Specific: Significance tests only tell you about the specific sample you have, not about how your results might generalize to a larger population. Thus, they might give a false sense of security.
Better Approaches: Other methods, like checking standardized differences or variance ratios (discussed earlier), are not affected by sample size and provide a more reliable assessment of balance.


Do not use c-statistics or the area under the curve (AUC) to measure propensity score performance. The use of these measures is questionable, as propensity scores are intended for reducing confounding and not for predictive modeling (Stuart 2010). 

Group balance = covariates are distributed similarly in both groups

Things to check for balance = significance testing, standardized differences (between means and prevalences), variance checks, interactions between variables are similar between groups, absolute standardized mean difference for each baseline factor

The other approaches are stratification by the propensity score, using the propensity score for inverse probability of treatment weighting, and including the propensity score as a regression covariate

TODO with or without replacement?

Summary and Explanation of the Systematic Review on Propensity Score Matching in Cardiovascular Surgery Literature
1. Propensity Score Matching Methods
Lack of Detail: Over half of the studies (52%) did not adequately describe how propensity score matching (PSM) was performed. This lack of detail included not specifying the type of matching (e.g., greedy or nearest neighbor) and failing to provide information on the caliper width, which is crucial for understanding the similarity required between matched pairs.
Impact: Without this information, it becomes difficult for other researchers to replicate the study or assess the validity of the matching process.
2. Assessing Balance Between Treated and Untreated Subjects
Reporting Issues: A significant number of studies (18%) did not report whether matching successfully balanced the baseline characteristics between treated and untreated subjects.
Use of Inappropriate Methods: The majority of studies (58%) that did report on balance used inappropriate statistical tests that did not account for the matched nature of the data, such as traditional hypothesis testing methods. None of the studies used recommended methods like standardized differences, which are not influenced by sample size and are more appropriate for assessing balance in matched samples.
3. Estimating the Effect of Treatment or Exposure on Outcomes
Inappropriate Analysis: Only 13% of studies used appropriate statistical methods for analyzing matched data, such as McNemar’s test or conditional logistic regression. Most studies (65%) used methods that are inappropriate for matched data, such as the log-rank test, standard Cox proportional hazards models, and regular logistic regression.
Importance of Correct Analysis: Using the wrong methods can lead to biased estimates of treatment effects, undermining the validity of the study's conclusions.

TODO:::: propensity score approaches = matching, subclassifications, covariate adjustment, and inverse probability weighting

-----
Step 1: Identify That PSM Is Viable and Appropriate
When to Use PSM: PSM is appropriate for nonrandomized, observational data where there may be imbalances in baseline characteristics between treatment groups that could lead to confounding.
Key Considerations: Ensure that data includes potential confounders and outcome variables. Identify imbalances between groups to justify the need for PSM.
Example: In a study comparing oxygen support in neonates, significant baseline imbalances between groups (e.g., weight, prior surgery) justify the use of PSM to address these differences.
Step 2: Calculate the Propensity Scores
Definition: Propensity scores represent the probability of a subject receiving a treatment based on observed covariates.
Calculation: Use logistic regression to estimate the propensity scores, where treatment status is the dependent variable, and covariates are the predictors.
Choosing Covariates: Include covariates related to both the treatment and the outcome to reduce bias effectively. True confounders should be prioritized.
Overlap Requirement: Ensure there is sufficient overlap in propensity scores between groups to allow matching.
Step 3: Match Subjects on the Propensity Scores
Matching Process: Pair treated and untreated subjects with similar propensity scores to create balanced groups.
Matching Options: Choose between 1-to-1 matching, k-to-1 matching, with or without replacement, and methods like optimal or greedy matching.
Caliper Width: Set a caliper width (e.g., 0.2 times the standard deviation of the logit of propensity scores) to control how closely matched pairs need to be.
Step 4: Assess Balance Diagnostics to Determine the Quality of the Matching
Assessing Balance: Check if the matching process has balanced the baseline covariates between the treatment and control groups.
Key Metrics:
Absolute Standardized Mean Difference: A value <0.1 indicates good balance.
Reduction in Pseudo R²: A decrease in pseudo R² after matching suggests improved balance.
Graphical Assessments: Use box plots, bar plots, and standardized mean difference plots to visually inspect balance.
Revising the Model: If poor balance is observed, consider adjusting the propensity score model or the matching process.
Step 5: Analyze the Propensity-Matched Cohort
Appropriate Analysis Techniques:
Binary Outcomes: Use conditional logistic regression to account for the matched pairs.
Continuous Outcomes: Apply generalized estimating equations or paired t-tests.
Survival/Time-to-Event Outcomes: Use appropriate survival analysis techniques considering the matched nature of the data.
Comparison of Results: Compare results before and after PSM to assess the impact of controlling for confounding variables. PSM often reduces the effect size compared to unadjusted analyses but provides more reliable estimates.
TL;DR
Determine if PSM is appropriate for your study by identifying baseline imbalances in your data.
Calculate propensity scores using logistic regression based on covariates related to treatment and outcome.
Match subjects based on these scores to create balanced treatment and control groups.
Assess balance between groups post-matching using standardized mean differences and other diagnostics.
Analyze the matched cohort with statistical methods that account for the matched pairs, ensuring that the analysis is robust against confounding.

A recent study found that matching on the logit of the propensity score using calipers of width 0.2 of the standard deviation of the logit of the propensity score tended to have superior performance compared with other competing methods. 

nearest neighbor caliper matching without replacement (random order or closest distance) be used when forming pairs of treated and untreated subjects with similar values of the propensity score.

# TODO checking inter categorical relationships between the PROMs (logistic regression? chi square tests?)

